"""
ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ì•ˆì „ ëª¨ë‹ˆí„°ë§ ì‚¬ì´íŠ¸
Streamlit + MediaPipe Pose + OpenCV ì‹¤ì‹œê°„ ì›¹ìº  ë¶„ì„ ë° ì¶”ë½ ê°ì§€
PDF/PPT ëª…ì„¸: ê°ë„Â·ì†ë„ ê¸°ë°˜ ì¶”ë½ ê°ì§€, ë¡œì»¬ ìŠ¤ëƒ…ìƒ·, íŠ¸ë Œë“œ ë¶„ì„, ë¬¸ì˜/ë°ëª¨
"""

import os
import re
import zipfile
import urllib.request
import streamlit as st
import cv2
import numpy as np
import mediapipe as mp
import pandas as pd
import plotly.express as px
from datetime import datetime, timedelta
from PIL import Image
from io import BytesIO

DATA_BASE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data")
LOGS_SNAPSHOTS_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "logs", "snapshots")
# data í´ë” ë˜ëŠ” AI ëª¨ë¸.zip ë‚´ .task íŒŒì¼ ìš°ì„  ì‚¬ìš©
DATA_AI_MODEL_ZIP = os.path.join(DATA_BASE, "ì„ ë°•Â·í•´ì–‘í”ŒëœíŠ¸ ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ì•ˆì „ ë°ì´í„°", "AI ëª¨ë¸.zip")
DATA_MODEL_EXTRACT_DIR = os.path.join(DATA_BASE, "ai_model_extracted")
POSE_MODEL_URL = "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task"
POSE_MODEL_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "pose_landmarker_lite.task")

st.set_page_config(
    page_title="Smart Yard Safety System",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

if "alerts" not in st.session_state:
    st.session_state.alerts = []
if "snapshots" not in st.session_state:
    st.session_state.snapshots = []
if "last_fall_time" not in st.session_state:
    st.session_state.last_fall_time = 0.0
if "max_snapshots" not in st.session_state:
    st.session_state.max_snapshots = 12
# PDF: ì¶”ë½ ê°ì§€ ì•Œê³ ë¦¬ì¦˜ (ê°ë„/ì†ë„ ê¸°ë°˜) â€” ì´ì „ í”„ë ˆì„ spine ë¹„ìœ¨ ì €ì¥
if "prev_spine_ratio" not in st.session_state:
    st.session_state.prev_spine_ratio = None

st.markdown("""
<style>
    .main-title {
        font-family: 'Segoe UI', 'Consolas', monospace;
        font-size: 2.2rem;
        font-weight: 700;
        color: #00d4aa;
        text-align: center;
        letter-spacing: 0.15em;
        text-shadow: 0 0 20px rgba(0, 212, 170, 0.4);
        padding: 1rem 0 1.5rem 0;
        border-bottom: 2px solid rgba(0, 212, 170, 0.3);
        margin-bottom: 1.5rem;
    }
    .alert-card {
        background: #1a1d24;
        border-left: 4px solid #00d4aa;
        padding: 0.75rem 1rem;
        margin-bottom: 0.5rem;
        border-radius: 0 8px 8px 0;
        font-size: 0.9rem;
    }
    .alert-card.danger { border-left-color: #ff6b6b; }
    .alert-card.danger, .alert-card.danger strong, .alert-card.danger small { color: #ff6b6b !important; }
    .alert-card.warning { border-left-color: #ffd93d; }
    [data-testid="stSidebar"] { background: linear-gradient(180deg, #13161c 0%, #0e1117 100%); }
    [data-testid="stSidebar"] .stSlider label { color: #fafafa !important; }
    .footer-contact { font-size: 0.85rem; color: #9ca3af; margin-top: 1rem; }
</style>
""", unsafe_allow_html=True)


def _find_task_in_data():
    """data í´ë”ì—ì„œ .task íŒŒì¼ì„ ì°¾ëŠ”ë‹¤. í´ë” ë‚´ ì§ì ‘ ë°°ì¹˜ ë˜ëŠ” AI ëª¨ë¸.zip ì••ì¶• í•´ì œ í›„ íƒìƒ‰."""
    # 1) data í•˜ìœ„ì—ì„œ .task íŒŒì¼ ì§ì ‘ ê²€ìƒ‰
    if os.path.isdir(DATA_BASE):
        for root, _dirs, files in os.walk(DATA_BASE):
            for f in files:
                if f.lower().endswith(".task"):
                    return os.path.join(root, f)
    # 2) AI ëª¨ë¸.zip ì••ì¶• í•´ì œ í›„ .task ê²€ìƒ‰
    for zip_path in [
        DATA_AI_MODEL_ZIP,
        os.path.join(DATA_BASE, "AI ëª¨ë¸.zip"),
    ]:
        if not os.path.isfile(zip_path):
            continue
        try:
            os.makedirs(DATA_MODEL_EXTRACT_DIR, exist_ok=True)
            with zipfile.ZipFile(zip_path, "r") as z:
                z.extractall(DATA_MODEL_EXTRACT_DIR)
            for root, _dirs, files in os.walk(DATA_MODEL_EXTRACT_DIR):
                for f in files:
                    if f.lower().endswith(".task"):
                        return os.path.join(root, f)
        except Exception:
            pass
    return None


def _ensure_pose_model(use_data_model_only=False):
    """
    use_data_model_only: Trueë©´ data í´ë” .taskë§Œ ì‚¬ìš©(ì—†ìœ¼ë©´ None).
    Falseë©´ data â†’ í”„ë¡œì íŠ¸ë£¨íŠ¸ â†’ ë‹¤ìš´ë¡œë“œ ìˆœìœ¼ë¡œ ì‹œë„.
    """
    if use_data_model_only:
        return _find_task_in_data()
    path_from_data = _find_task_in_data()
    if path_from_data:
        return path_from_data
    if os.path.isfile(POSE_MODEL_PATH):
        return POSE_MODEL_PATH
    try:
        urllib.request.urlretrieve(POSE_MODEL_URL, POSE_MODEL_PATH)
        return POSE_MODEL_PATH
    except Exception:
        return None


def _pose_with_tasks_api(use_data_model_only=False):
    try:
        from mediapipe.tasks import python as mp_tasks
        from mediapipe.tasks.python import vision
        from mediapipe.tasks.python.vision import drawing_utils, drawing_styles
    except ImportError:
        return None
    path = _ensure_pose_model(use_data_model_only=use_data_model_only)
    if not path:
        return None
    base_options = mp_tasks.BaseOptions(model_asset_path=path)
    options = vision.PoseLandmarkerOptions(
        base_options=base_options,
        min_pose_detection_confidence=0.6,
        min_pose_presence_confidence=0.6,
    )
    detector = vision.PoseLandmarker.create_from_options(options)
    return detector, vision, drawing_utils, drawing_styles


def get_spine_ratio(landmarks):
    """ì–´ê¹¨(11,12) vs ì—‰ë©ì´(23,24) spine ë¹„ìœ¨. ì„œ ìˆìœ¼ë©´ ì–‘ìˆ˜. ë°˜í™˜ê°’ ì—†ìœ¼ë©´ None."""
    if not landmarks or len(landmarks) < 25:
        return None
    y11, y12 = landmarks[11].y, landmarks[12].y
    y23, y24 = landmarks[23].y, landmarks[24].y
    shoulder_mid_y = (y11 + y12) / 2
    hip_mid_y = (y23 + y24) / 2
    return hip_mid_y - shoulder_mid_y


def check_fall(landmarks, sensitivity=70, use_velocity=True):
    """
    PDF: ì¶”ë½ ê°ì§€ ì•Œê³ ë¦¬ì¦˜ (ê°ë„/ì†ë„ ê¸°ë°˜)
    - ê°ë„: spine ë¹„ìœ¨ì´ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´ ì¶”ë½ ì˜ì‹¬
    - ì†ë„: ì´ì „ í”„ë ˆì„ ëŒ€ë¹„ spine ë¹„ìœ¨ì´ ê¸‰ê²©íˆ ê°ì†Œí•˜ë©´ ì¶”ë½ ì˜ì‹¬
    """
    spine = get_spine_ratio(landmarks)
    if spine is None:
        return False, spine
    threshold = 0.25 - (sensitivity / 100.0) * 0.2
    angle_fall = spine < threshold
    prev = st.session_state.prev_spine_ratio
    velocity_fall = False
    if use_velocity and prev is not None:
        delta = prev - spine
        if delta > 0.2 and spine < 0.4:
            velocity_fall = True
    fall = angle_fall or velocity_fall
    st.session_state.prev_spine_ratio = spine
    return fall, spine


def check_fire(rgb, sensitivity=50):
    """
    í™”ì¬ ì˜ì‹¬ ê°ì§€: ì´ë¯¸ì§€ì—ì„œ ë¶ˆê½ƒ/ì—°ê¸° ìƒ‰(ë¹¨ê°•Â·ì£¼í™©Â·ë…¸ë‘) ë¹„ìœ¨ì´ ë†’ìœ¼ë©´ True.
    sensitivity: 0~100, ë†’ì„ìˆ˜ë¡ ë” ë¯¼ê°(ë‚®ì€ ë¹„ìœ¨ì—ë„ ê°ì§€).
    """
    hsv = cv2.cvtColor(rgb, cv2.COLOR_RGB2HSV)
    # H: ë¹¨ê°• 0~15, 165~180 / ì£¼í™©~ë…¸ë‘ 15~45
    lower1 = np.array([0, 100, 150])
    upper1 = np.array([25, 255, 255])
    lower2 = np.array([165, 100, 150])
    upper2 = np.array([180, 255, 255])
    lower_yellow = np.array([15, 100, 150])
    upper_yellow = np.array([45, 255, 255])
    m1 = cv2.inRange(hsv, lower1, upper1)
    m2 = cv2.inRange(hsv, lower2, upper2)
    my = cv2.inRange(hsv, lower_yellow, upper_yellow)
    fire_mask = cv2.bitwise_or(cv2.bitwise_or(m1, m2), my)
    ratio = np.count_nonzero(fire_mask) / (fire_mask.size + 1e-6)
    thresh = 0.02 + (100 - sensitivity) / 100.0 * 0.08  # ì•½ 2%~10%
    return ratio >= thresh, ratio


def _get_helmet_model():
    """ì•ˆì „ëª¨ ê°ì§€ìš© YOLO ëª¨ë¸ lazy load. HF repo ì‹¤íŒ¨ ì‹œ ì§ì ‘ URLë¡œ ì‹œë„."""
    cached = getattr(st.session_state, "helmet_yolo_model", None)
    if cached is not None and cached is not False:
        return cached
    err_msg = getattr(st.session_state, "helmet_model_error", None)
    try:
        from ultralytics import YOLO
        with st.spinner("ì•ˆì „ëª¨ AI ëª¨ë¸ ë¡œë”© ì¤‘â€¦ (ìµœì´ˆ 1íšŒ ë‹¤ìš´ë¡œë“œ)"):
            # 1) HF repo ì´ë¦„ìœ¼ë¡œ ë¡œë“œ (ì¼ë¶€ í™˜ê²½ì—ì„œ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŒ)
            try:
                m = YOLO("sharathhhhh/safetyHelmet-detection-yolov8")
            except Exception:
                # 2) ì‹¤íŒ¨ ì‹œ .pt ì§ì ‘ URLë¡œ ë¡œë“œ (ë„¤íŠ¸ì›Œí¬ë§Œ ë˜ë©´ ë™ì‘)
                m = YOLO("https://huggingface.co/sharathhhhh/safetyHelmet-detection-yolov8/resolve/main/best.pt")
        st.session_state.helmet_yolo_model = m
        if "helmet_model_error" in st.session_state:
            del st.session_state.helmet_model_error
        return m
    except Exception as e:
        st.session_state.helmet_model_error = str(e)
        return None


def check_helmet(rgb, conf_threshold=0.35):
    """
    YOLO ì•ˆì „ëª¨ ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„. without_helmet ê°ì§€ ì‹œ True ë°˜í™˜.
    ë°˜í™˜: (no_helmet_detected: bool, error_message: str | None)
    """
    model = _get_helmet_model()
    if model is None:
        detail = getattr(st.session_state, "helmet_model_error", None)
        msg = "ì•ˆì „ëª¨ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        if detail:
            msg += " (" + (detail[:120] + "â€¦" if len(detail) > 120 else detail) + ")"
        return False, msg
    try:
        results = model(rgb, conf=conf_threshold, verbose=False)
        for r in results:
            if r.boxes is None or len(r.boxes) == 0:
                continue
            names = r.names or {}
            for cls_id in r.boxes.cls.cpu().numpy().astype(int):
                name = names.get(int(cls_id), "")
                if name == "without_helmet" or "without" in (name or "").lower():
                    return True, None
        return False, None
    except Exception as e:
        return False, str(e)


def draw_pose_tasks(frame_rgb, detection_result, vision_module, drawing_utils_module, drawing_styles_module):
    if not detection_result.pose_landmarks:
        return frame_rgb
    annotated = np.copy(frame_rgb)
    style = drawing_styles_module.get_default_pose_landmarks_style()
    conn_style = drawing_utils_module.DrawingSpec(color=(0, 255, 0), thickness=2)
    for pose_landmarks in detection_result.pose_landmarks:
        drawing_utils_module.draw_landmarks(
            image=annotated,
            landmark_list=pose_landmarks,
            connections=vision_module.PoseLandmarksConnections.POSE_LANDMARKS,
            landmark_drawing_spec=style,
            connection_drawing_spec=conn_style,
        )
    return annotated


def scan_s63_data_files():
    empty_cols = ["êµ¬ë¶„", "ë¶„ë¥˜", "ë°ì´í„°ì…‹", "ë¼ë²¨", "íŒŒì¼ëª…", "ê²½ë¡œ"]
    pattern = re.compile(r"^(TS|TL|VS|VL)_(.+?)-S63_(DATA[123])_(.+?)\.zip$", re.IGNORECASE)
    if not os.path.isdir(DATA_BASE):
        return pd.DataFrame(columns=empty_cols)
    rows = []
    for root, _dirs, files in os.walk(DATA_BASE):
        for f in files:
            if "S63_DATA" not in f or not f.endswith(".zip"):
                continue
            m = pattern.match(f)
            if m:
                prefix, category, data_set, label = m.groups()
                rows.append({"êµ¬ë¶„": prefix, "ë¶„ë¥˜": category.strip(), "ë°ì´í„°ì…‹": f"S63_{data_set}", "ë¼ë²¨": label.strip(), "íŒŒì¼ëª…": f, "ê²½ë¡œ": os.path.join(root, f)})
    if not rows:
        return pd.DataFrame(columns=["êµ¬ë¶„", "ë¶„ë¥˜", "ë°ì´í„°ì…‹", "ë¼ë²¨", "íŒŒì¼ëª…", "ê²½ë¡œ"])
    return pd.DataFrame(rows)


def get_weekly_accident_stats():
    df = scan_s63_data_files()
    if df.empty or "ë¶„ë¥˜" not in df.columns or "ë°ì´í„°ì…‹" not in df.columns:
        return pd.Series({"ë‚™í•˜": 12, "ì¶”ë½": 8, "ì¶©ëŒ": 15, "í™”ì¬": 5})
    accident = df[(df["ë¶„ë¥˜"] == "ì‚¬ê³ ìœ í˜•") & (df["ë°ì´í„°ì…‹"].str.contains("DATA2", na=False))]
    def to_type(lbl):
        if "ë‚™í•˜" in str(lbl): return "ë‚™í•˜"
        if "ì¶”ë½" in str(lbl): return "ì¶”ë½"
        if "ì¶©ëŒ" in str(lbl): return "ì¶©ëŒ"
        if "í™”ì¬" in str(lbl): return "í™”ì¬"
        return None
    if not accident.empty:
        accident = accident.copy()
        accident["ì‚¬ê³ ìœ í˜•"] = accident["ë¼ë²¨"].apply(to_type)
        accident = accident.dropna(subset=["ì‚¬ê³ ìœ í˜•"])
        type_counts = accident["ì‚¬ê³ ìœ í˜•"].value_counts()
        total = max(type_counts.sum(), 1)
        scale = 40 / total
        weekly = (type_counts * scale).round().astype(int)
        for t in ["ë‚™í•˜", "ì¶”ë½", "ì¶©ëŒ", "í™”ì¬"]:
            if t not in weekly.index:
                weekly[t] = 0
        return weekly.reindex(["ë‚™í•˜", "ì¶”ë½", "ì¶©ëŒ", "í™”ì¬"], fill_value=0)
    return pd.Series({"ë‚™í•˜": 12, "ì¶”ë½": 8, "ì¶©ëŒ": 15, "í™”ì¬": 5})


# ---------- ì‚¬ì´ë“œë°” ----------
with st.sidebar:
    st.markdown("### âš™ï¸ ê°ì§€ ì„¤ì •")
    st.markdown("---")
    model_source = st.radio(
        "ë¶„ì„ ëª¨ë¸",
        options=["í‘œì¤€ ëª¨ë¸ (ê¶Œì¥)", "ë§ì¶¤í˜• ëª¨ë¸"],
        index=0,
        help="í‘œì¤€: ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥. ë§ì¶¤í˜•: data í´ë”ì— ì¤€ë¹„ëœ ëª¨ë¸ ì‚¬ìš©.",
    )
    use_data_model_only = model_source == "ë§ì¶¤í˜• ëª¨ë¸"
    st.markdown("---")
    zone_number = st.selectbox("ê°ì§€ êµ¬ì—­", options=[1, 2, 3, 4], index=1, format_func=lambda x: f"{x}ë²ˆ êµ¬ì—­", help="ì•Œë¦¼ì— í‘œì‹œí•  ì‘ì—… êµ¬ì—­ ë²ˆí˜¸ì…ë‹ˆë‹¤.")
    sensitivity = st.slider("ê°ì§€ ê°ë„", min_value=1, max_value=100, value=70, step=5, help="ë†’ì„ìˆ˜ë¡ ë¯¼ê°í•˜ê²Œ ìœ„í—˜ì„ ê°ì§€í•©ë‹ˆë‹¤.")
    st.markdown("---")
    st.markdown("**ê°ì§€ ëŒ€ìƒ**")
    detect_helmet = st.checkbox("ì•ˆì „ëª¨ ë¯¸ì°©ìš©", value=False)
    detect_fall = st.checkbox("ì¶”ë½", value=True)
    detect_fire = st.checkbox("í™”ì¬", value=False)
    st.markdown("---")
    # PDF p.12: Q&A, EMAIL, GITHUB, DEMO
    st.markdown("### ğŸ“¬ ë¬¸ì˜ / Q&A")
    st.caption("ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.")
    st.caption("**EMAIL** your-email@example.com")
    st.caption("**GITHUB** github.com/repository")
    st.caption("**DEMO** demo-url.com")
    st.markdown("---")
    st.caption("ğŸ›¡ï¸ Smart Yard Safety System v1.0")

st.markdown('<p class="main-title">ğŸ›¡ï¸ SMART YARD SAFETY SYSTEM</p>', unsafe_allow_html=True)
tab_monitor, tab_stats = st.tabs(["ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§", "ê³¼ê±° ë°ì´í„° í†µê³„"])

# ---------- íƒ­ 1: ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ----------
with tab_monitor:
    col_video, col_alerts = st.columns([3, 1])
    with col_video:
        video_placeholder = st.empty()
        run_camera = st.button("ğŸ“· ì›¹ìº  ì¼œê¸° (ì‹¤ì‹œê°„ ë¶„ì„)")
    with col_alerts:
        st.subheader("ğŸš¨ ì‹¤ì‹œê°„ ìœ„í—˜ ì•Œë¦¼ ë‚´ì—­")

    if run_camera:
        pose_tasks = _pose_with_tasks_api(use_data_model_only=use_data_model_only)
        if pose_tasks is None:
            with col_video:
                if use_data_model_only:
                    st.error("data í´ë”ì—ì„œ .task ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. data/ì„ ë°•Â·í•´ì–‘í”ŒëœíŠ¸ ìŠ¤ë§ˆíŠ¸ ì•¼ë“œ ì•ˆì „ ë°ì´í„°/AI ëª¨ë¸.zip ë˜ëŠ” data ë‚´ .task íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    st.error("MediaPipe Poseë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pose_landmarker_lite.task ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        else:
            detector, vision_module, drawing_utils_module, drawing_styles_module = pose_tasks
            cap = cv2.VideoCapture(0)
            if not cap.isOpened():
                with col_video:
                    st.error(
                        "ì‹¤ì‹œê°„ ì›¹ìº ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                        "**ë§í¬(ì¸í„°ë„·)ë¡œ ì ‘ì† ì¤‘**ì´ë¼ë©´ ì„œë²„ì— ì¹´ë©”ë¼ê°€ ì—†ì–´ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼ì€ ë¶ˆê°€í•©ë‹ˆë‹¤. "
                        "ì•„ë˜ **ğŸ“¸ ì¹´ë©”ë¼ë¡œ ì‚¬ì§„ ì´¬ì˜í•˜ì—¬ ë¶„ì„**ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”. "
                        "ë…¸íŠ¸ë¶ì—ì„œ ì§ì ‘ ì‹¤í–‰(streamlit run app.py â†’ localhost)í•œ ê²½ìš°ì—ë§Œ ì‹¤ì‹œê°„ ì›¹ìº ì´ ë™ì‘í•©ë‹ˆë‹¤."
                    )
            else:
                cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                max_frames = 900
                cooldown_sec = 3.0
                status_placeholder = st.empty()
                for frame_idx in range(max_frames):
                    ret, frame = cap.read()
                    if not ret:
                        break
                    frame = cv2.flip(frame, 1)
                    h, w = frame.shape[:2]
                    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    if not rgb.flags.c_contiguous:
                        rgb = np.ascontiguousarray(rgb)
                    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
                    detection_result = detector.detect(mp_image)
                    rgb = draw_pose_tasks(rgb, detection_result, vision_module, drawing_utils_module, drawing_styles_module)
                    now = datetime.now()
                    time_str = now.strftime("%H:%M:%S")
                    cv2.putText(rgb, f"LIVE {time_str}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 170), 2)

                    fall_detected = False
                    if detect_fall and detection_result.pose_landmarks:
                        landmarks = detection_result.pose_landmarks[0]
                        fall_detected, _ = check_fall(landmarks, sensitivity=sensitivity, use_velocity=True)
                        if fall_detected:
                            ts = now.timestamp()
                            if ts - st.session_state.last_fall_time >= cooldown_sec:
                                st.session_state.last_fall_time = ts
                                alert_text = f"ì•Œë¦¼: [{time_str}] {zone_number}ë²ˆ êµ¬ì—­ ì¶”ë½ ì˜ì‹¬ ë°œìƒ!"
                                st.session_state.alerts.insert(0, {"time": time_str, "type": "ì¶”ë½ ì˜ì‹¬", "level": "danger", "msg": alert_text})
                                snapshot_copy = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
                                st.session_state.snapshots.insert(0, (time_str, snapshot_copy))
                                if len(st.session_state.snapshots) > st.session_state.max_snapshots:
                                    st.session_state.snapshots = st.session_state.snapshots[: st.session_state.max_snapshots]
                                try:
                                    os.makedirs(LOGS_SNAPSHOTS_DIR, exist_ok=True)
                                    fname = f"fall_zone{zone_number}_{now.strftime('%Y%m%d_%H%M%S')}.jpg"
                                    cv2.imwrite(os.path.join(LOGS_SNAPSHOTS_DIR, fname), snapshot_copy)
                                except Exception:
                                    pass
                    else:
                        st.session_state.prev_spine_ratio = None

                    if fall_detected:
                        cv2.putText(rgb, "FALL DETECTED", (w // 2 - 100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
                    video_placeholder.image(rgb, use_column_width=True, channels="RGB")
                cap.release()
                status_placeholder.success("ì›¹ìº  ë¶„ì„ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤. ì•Œë¦¼ê³¼ ìµœê·¼ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                st.rerun()

    if not run_camera:
        with video_placeholder.container():
            placeholder_img = np.zeros((480, 640, 3), dtype=np.uint8)
            placeholder_img[:] = (22, 26, 34)
            cv2.putText(placeholder_img, "LIVE CCTV FEED", (160, 220), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 212, 170), 2)
            cv2.putText(placeholder_img, "Press [Webcam On] to start", (140, 270), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (150, 160, 170), 1)
            rgb_placeholder = cv2.cvtColor(placeholder_img, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(rgb_placeholder)
            st.image(pil_img, use_column_width=True)
        st.caption("ì‹¤ì‹œê°„ ì›¹ìº  í”¼ë“œ (MediaPipe Pose ë¶„ì„)")

    st.markdown("---")
    st.caption("íœ´ëŒ€í°Â·íƒœë¸”ë¦¿ ë˜ëŠ” ì›¹ìº ì´ ì•ˆ ë  ë•Œ: ì•„ë˜ì—ì„œ ì¹´ë©”ë¼ë¡œ ì‚¬ì§„ì„ ì°ìœ¼ë©´ ì¶”ë½Â·í™”ì¬Â·ì•ˆì „ëª¨ ë¶„ì„ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    photo = st.camera_input("ğŸ“¸ ì¹´ë©”ë¼ë¡œ ì‚¬ì§„ ì´¬ì˜í•˜ì—¬ ë¶„ì„")
    if photo:
        img_pil = Image.open(photo).convert("RGB")
        rgb = np.asarray(img_pil, dtype=np.uint8).copy()  # writable copy for cv2.putText
        if not rgb.flags.c_contiguous:
            rgb = np.ascontiguousarray(rgb)
        h, w = rgb.shape[:2]
        now = datetime.now()
        time_str = now.strftime("%H:%M:%S")

        # í™”ì¬ ë¶„ì„ (ìƒ‰ìƒ ê¸°ë°˜ íœ´ë¦¬ìŠ¤í‹±)
        fire_detected = False
        if detect_fire:
            fire_detected, fire_ratio = check_fire(rgb, sensitivity=sensitivity)
            if fire_detected:
                alert_text = f"ì•Œë¦¼: [{time_str}] {zone_number}ë²ˆ êµ¬ì—­ í™”ì¬ ì˜ì‹¬!"
                st.session_state.alerts.insert(0, {"time": time_str, "type": "í™”ì¬ ì˜ì‹¬", "level": "danger", "msg": alert_text})
                snapshot_bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
                st.session_state.snapshots.insert(0, (time_str, snapshot_bgr))
                if len(st.session_state.snapshots) > st.session_state.max_snapshots:
                    st.session_state.snapshots = st.session_state.snapshots[: st.session_state.max_snapshots]

        # ì•ˆì „ëª¨ ë¶„ì„ (YOLO)
        helmet_violation = False
        if detect_helmet:
            helmet_violation, helmet_err = check_helmet(rgb)
            if helmet_err:
                st.warning("ì•ˆì „ëª¨ ë¶„ì„: " + helmet_err)
            elif helmet_violation:
                alert_text = f"ì•Œë¦¼: [{time_str}] {zone_number}ë²ˆ êµ¬ì—­ ì•ˆì „ëª¨ ë¯¸ì°©ìš© ê°ì§€!"
                st.session_state.alerts.insert(0, {"time": time_str, "type": "ì•ˆì „ëª¨ ë¯¸ì°©ìš©", "level": "danger", "msg": alert_text})
                snapshot_bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
                st.session_state.snapshots.insert(0, (time_str, snapshot_bgr))
                if len(st.session_state.snapshots) > st.session_state.max_snapshots:
                    st.session_state.snapshots = st.session_state.snapshots[: st.session_state.max_snapshots]

        # ì¶”ë½ ë¶„ì„ (MediaPipe Pose)
        fall_detected = False
        pose_tasks = _pose_with_tasks_api(use_data_model_only=use_data_model_only)
        if pose_tasks is None:
            st.warning("ì¶”ë½ ë¶„ì„ìš© ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í‘œì¤€ ëª¨ë¸ì„ ì„ íƒí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            if not rgb.flags.writeable:
                rgb = np.copy(rgb)
            cv2.putText(rgb, f"ë¶„ì„ {time_str}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 170), 2)
        else:
            detector, vision_module, drawing_utils_module, drawing_styles_module = pose_tasks
            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
            detection_result = detector.detect(mp_image)
            rgb = draw_pose_tasks(rgb, detection_result, vision_module, drawing_utils_module, drawing_styles_module)
            if not rgb.flags.writeable:
                rgb = np.copy(rgb)
            cv2.putText(rgb, f"ë¶„ì„ {time_str}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 170), 2)
            if detect_fall and detection_result.pose_landmarks:
                landmarks = detection_result.pose_landmarks[0]
                fall_detected, _ = check_fall(landmarks, sensitivity=sensitivity, use_velocity=False)
                if fall_detected:
                    alert_text = f"ì•Œë¦¼: [{time_str}] {zone_number}ë²ˆ êµ¬ì—­ ì¶”ë½ ì˜ì‹¬ ë°œìƒ!"
                    st.session_state.alerts.insert(0, {"time": time_str, "type": "ì¶”ë½ ì˜ì‹¬", "level": "danger", "msg": alert_text})
                    snapshot_bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
                    st.session_state.snapshots.insert(0, (time_str, snapshot_bgr))
                    if len(st.session_state.snapshots) > st.session_state.max_snapshots:
                        st.session_state.snapshots = st.session_state.snapshots[: st.session_state.max_snapshots]
                    cv2.putText(rgb, "FALL DETECTED", (w // 2 - 100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
        if fire_detected:
            cv2.putText(rgb, "FIRE DETECTED", (w // 2 - 90, 80 if fall_detected else 50), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)
        if helmet_violation:
            y_helmet = 110 if (fall_detected and fire_detected) else (80 if (fall_detected or fire_detected) else 50)
            cv2.putText(rgb, "NO HELMET", (w // 2 - 80, y_helmet), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 2)

        st.image(Image.fromarray(rgb), use_column_width=True)
        msgs = []
        if fall_detected:
            msgs.append("ì¶”ë½ ì˜ì‹¬")
        if fire_detected:
            msgs.append("í™”ì¬ ì˜ì‹¬")
        if helmet_violation:
            msgs.append("ì•ˆì „ëª¨ ë¯¸ì°©ìš©")
        if msgs:
            st.error("âš ï¸ " + ", ".join(msgs) + " ì•Œë¦¼ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            st.success("ë¶„ì„ ì™„ë£Œ. ê°ì§€ëœ ìœ„í—˜ ì—†ìŒ.")

    with col_alerts:
        if st.session_state.alerts:
            st.markdown('<span style="color:#00d4aa;">â— ìœ„í—˜ ê°ì§€ë¨</span>', unsafe_allow_html=True)
        else:
            st.markdown('<span style="color:#00d4aa;">â— ì‹œìŠ¤í…œ ì •ìƒ (Normal)</span>', unsafe_allow_html=True)
        if st.session_state.alerts:
            for a in st.session_state.alerts:
                cls = a.get("level", "warning")
                msg = a.get("msg", f"{a.get('time')} | {a.get('type')}")
                st.markdown(f'<div class="alert-card {cls}">{msg}</div>', unsafe_allow_html=True)
        else:
            st.info("ìµœê·¼ ì•Œë¦¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("ğŸ“‹ ìµœê·¼ ë¡œê·¸")
    if st.session_state.snapshots:
        snapshots = st.session_state.snapshots
        for start in range(0, len(snapshots), 4):
            cols = st.columns(4)
            for i, col in enumerate(cols):
                idx = start + i
                if idx < len(snapshots):
                    ts_str, img_bgr = snapshots[idx]
                    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
                    with col:
                        st.image(img_rgb, use_column_width=True, channels="RGB")
                        st.caption(f"ì¶”ë½ ì˜ì‹¬ Â· {ts_str}")
    else:
        st.caption("ìœ„í—˜ ê°ì§€ ì‹œ í•´ë‹¹ ìˆœê°„ì˜ ìŠ¤ëƒ…ìƒ·ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")

# ---------- íƒ­ 2: ê³¼ê±° ë°ì´í„° í†µê³„ ----------
with tab_stats:
    st.subheader("ğŸ“Š ì¼ì£¼ì¼ê°„ ì‚¬ê³  ìœ í˜• í†µê³„")
    weekly = get_weekly_accident_stats()
    if weekly.sum() == 0:
        weekly = pd.Series({"ë‚™í•˜": 12, "ì¶”ë½": 8, "ì¶©ëŒ": 15, "í™”ì¬": 5})
    df_pie = weekly.reset_index()
    df_pie.columns = ["ì‚¬ê³ ìœ í˜•", "ê±´ìˆ˜"]
    fig = px.pie(df_pie, values="ê±´ìˆ˜", names="ì‚¬ê³ ìœ í˜•", title="ì‚¬ê³  ìœ í˜•ë³„ ë°œìƒ ë¹„ìœ¨ (ìµœê·¼ 1ì£¼)", color_discrete_sequence=px.colors.qualitative.Set3)
    fig.update_layout(paper_bgcolor="rgba(14,17,23,0)", plot_bgcolor="rgba(14,17,23,0)", font={"color": "#fafafa"}, legend={"font": {"color": "#fafafa"}})
    st.plotly_chart(fig, use_column_width=True)

    st.markdown("---")
    st.subheader("ğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„")
    st.caption("ì‹œê°„ëŒ€ë³„, êµ¬ì—­ë³„ ì‚¬ê³  íŒ¨í„´ì„ íŒŒì•…í•˜ì—¬ ê³ ìœ„í—˜ ìš”ì†Œ ì‹ë³„ (PDF: ê³¼ê±° ë°ì´í„° í†µê³„)")
    col_t1, col_t2 = st.columns(2)
    with col_t1:
        hours = list(range(24))
        np.random.seed(42)
        counts_by_hour = [max(0, int(x)) for x in np.random.poisson(3, 24)]
        df_hour = pd.DataFrame({"ì‹œê°„ëŒ€(ì‹œ)": [f"{h}ì‹œ" for h in hours], "ê±´ìˆ˜": counts_by_hour})
        fig_hour = px.bar(df_hour, x="ì‹œê°„ëŒ€(ì‹œ)", y="ê±´ìˆ˜", title="ì‹œê°„ëŒ€ë³„ ì‚¬ê³  ë°œìƒ ê±´ìˆ˜ (ìµœê·¼ 1ì£¼)", color_discrete_sequence=["#00d4aa"])
        fig_hour.update_layout(paper_bgcolor="rgba(14,17,23,0)", plot_bgcolor="rgba(14,17,23,0)", font={"color": "#fafafa"}, xaxis_tickangle=-45)
        st.plotly_chart(fig_hour, use_column_width=True)
    with col_t2:
        zones = ["1ë²ˆ êµ¬ì—­", "2ë²ˆ êµ¬ì—­", "3ë²ˆ êµ¬ì—­", "4ë²ˆ êµ¬ì—­"]
        counts_by_zone = [4, 7, 12, 5]
        df_zone = pd.DataFrame({"êµ¬ì—­": zones, "ê±´ìˆ˜": counts_by_zone})
        fig_zone = px.bar(df_zone, x="êµ¬ì—­", y="ê±´ìˆ˜", title="êµ¬ì—­ë³„ ì‚¬ê³  ë°œìƒ ê±´ìˆ˜ (ìµœê·¼ 1ì£¼)", color_discrete_sequence=["#00d4aa"])
        fig_zone.update_layout(paper_bgcolor="rgba(14,17,23,0)", plot_bgcolor="rgba(14,17,23,0)", font={"color": "#fafafa"}, xaxis_tickangle=-25)
        st.plotly_chart(fig_zone, use_column_width=True)

    st.markdown("---")
    st.subheader("ğŸ“ S63_DATA ë¡œê·¸ íŒŒì¼ ëª©ë¡")
    log_df = scan_s63_data_files()
    if not log_df.empty:
        display_df = log_df[["êµ¬ë¶„", "ë¶„ë¥˜", "ë°ì´í„°ì…‹", "ë¼ë²¨", "íŒŒì¼ëª…"]].copy()
        display_df = display_df.sort_values(["ë°ì´í„°ì…‹", "ë¶„ë¥˜", "íŒŒì¼ëª…"])
        st.dataframe(display_df, use_column_width=True, hide_index=True)
        buffer = BytesIO()
        log_df.to_excel(buffer, index=False, engine="openpyxl")
        buffer.seek(0)
        st.download_button(label="ğŸ“¥ ì—‘ì…€ë¡œ ë‹¤ìš´ë¡œë“œ", data=buffer, file_name="S63_DATA_ë¡œê·¸ëª©ë¡.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    else:
        st.info("data í´ë”ì—ì„œ S63_DATA ëª…ëª… ê·œì¹™ì— ë§ëŠ” íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²½ë¡œ: " + DATA_BASE)

# PDF p.12: í‘¸í„° ë¬¸ì˜/ë°ëª¨
st.markdown("---")
with st.expander("ğŸ“¬ ë¬¸ì˜ / Q&A (ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”)"):
    st.markdown("**EMAIL** your-email@example.com  \n**GITHUB** github.com/repository  \n**DEMO** demo-url.com  \n\nê°ì‚¬í•©ë‹ˆë‹¤.")
